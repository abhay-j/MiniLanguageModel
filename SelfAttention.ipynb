{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7324c85-f566-4e49-b3d0-f1d5f3d77d8b",
   "metadata": {},
   "source": [
    "# Self-attention with trainable  Query, Key, Value weights\n",
    "- Todo:\n",
    "- create query, key, value weight matrices to transofrm the input embeddings.\n",
    "- We need these weight metrices because without these the relationship between tokens like \"journey\" and \"starts\" would indeed be fixed across all contexts. We'd be limited to using only the original embedding space to determine attention\n",
    "- We multiply the input embeddings with the query, key, value weight matrices\n",
    "- we derive the attention scores by multiplying the query and the key matrix.\n",
    "- These attention scores are normalised by applying softmax to derive attention weights.\n",
    "- The attention weight matrix is multiplied by the value matrix to derive our context vecots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "757debdd-63ad-4beb-9c93-0a24708bced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "inputs = torch.tensor(\n",
    "    [[0.43, 0.15, 0.89],# Your (x^1)\n",
    "   [0.55, 0.87, 0.66],  # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64],  # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33],  # with     (x^4)\n",
    "   [0.77, 0.25, 0.10],  # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]]  # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9db1ad89-26d7-41bc-a13f-e6e70bf63bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32d7b323-2eca-4374-b6b1-75b609bd35b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create the weight matrices we will have to use the shape : inputs.shape[1] x no. of o/p dims we want to have\n",
    "#Note that in GPT-like models, the input and output dimensions are usually the same.\n",
    "x_2 = inputs[1]\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b260c5e-b83f-480e-a5ae-d2b56ff1659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad = False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad = False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cfeeed-5faf-4f77-84af-16e8739bc23b",
   "metadata": {},
   "source": [
    "- Tehse are the query, key, value weight matrices initialised with random values, these will be trained.\n",
    "- Note that we are setting requires_grad=False to reduce clutter in the outputs for illustration purposes.\n",
    "- If we were to use the weight matrices for model training, we would set requires_grad=True to update these matrices during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aad8d634-909d-4023-9f3f-90adc959f193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4306, 1.4551]) tensor([0.4433, 1.1419])\n"
     ]
    }
   ],
   "source": [
    "# computing the query, key, and value matrices for the input embedding \n",
    "query_2 = x_2 @ W_query\n",
    "key_2 = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "print(query_2, key_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe50fa1-b23b-4e15-bacc-151d7ea8347c",
   "metadata": {},
   "source": [
    "- Even though our temporary goal is to only compute the one context vector z(2), we still require the key and value vectors for all input elements.\n",
    "- This is because they are involved in computing the attention weights with respect to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b26e4e45-a4f1-4233-aa0a-1d8a72ce73aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys shape :torch.Size([6, 2]), values shape :torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value\n",
    "print (f\"keys shape :{keys.shape}, values shape :{values.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b78fe136-ba49-4fd3-8d63-d3ea6a752a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8524)\n"
     ]
    }
   ],
   "source": [
    "# attention score of query_2 with respect to only keys[1]\n",
    "keys_2 = keys[1]\n",
    "attention_score_query_2 = query_2.dot(keys_2)\n",
    "print(attention_score_query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f40b176f-a977-47d7-b937-6cf78716da81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
     ]
    }
   ],
   "source": [
    "# lets find out attention score for  query_2 with respect to all keys\n",
    "attention_scores_query_2 = query_2 @ keys.T\n",
    "print(attention_scores_query_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08858bf0-645c-4b69-8ae2-c0b114252804",
   "metadata": {},
   "source": [
    "- We compute the attention weights by scaling the attention scores and using the softmax function we used earlier.\n",
    "- The difference to earlier is that we now scale the attention scores by dividing them by the square root of the embedding dimension of the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af20e8c7-f306-4fb5-929b-bba513a4282e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention weights for q2: tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n"
     ]
    }
   ],
   "source": [
    "dim_k = keys.shape[-1]\n",
    "attention_weights_q2 = torch.softmax((attention_scores_query_2 /dim_k ** 0.5) , dim = -1)\n",
    "print(f\"attention weights for q2: {attention_weights_q2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec533a6-ab10-45c5-aea7-49140fde3671",
   "metadata": {},
   "source": [
    "- We now compute the context vector as a weighted sum over the value vectors.\n",
    "- Here, the attention weights serve as a weighting factor that weighs the respective importance of each value vector.\n",
    "- We can use matrix multiplication to obtain the output in one step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "538739f4-a1ad-4b61-8fd2-aa492b808f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3061, 0.8210])\n"
     ]
    }
   ],
   "source": [
    "context_vectors_z2 = attention_weights_q2 @ values\n",
    "print(context_vectors_z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace0d1bc-cfde-447b-9b84-d3c63974dd04",
   "metadata": {},
   "source": [
    "- Now, lets implement a class so that we could do this for all the input embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17a7ec09-fa0f-45cd-9e5b-4797089da3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SelfAttentionV1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad = False)\n",
    "        self.W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad = False)\n",
    "        self.W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad = False)\n",
    "    def forward(self, x):\n",
    "        queries = x @ self.W_query\n",
    "        keys = x @ self.W_key\n",
    "        values = x @ self.W_value\n",
    "\n",
    "        attention_scores = queries @ keys.T\n",
    "        attention_weights = torch.softmax(attention_scores / keys.shape[-1] ** 0.5, dim = -1)\n",
    "        context_vectors = attention_weights @ values \n",
    "        return context_vectors\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e000cd88-11a9-4b9c-95d9-5055bf0f21fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4035, 1.0391],\n",
      "        [1.4410, 1.0669],\n",
      "        [1.4391, 1.0655],\n",
      "        [1.3786, 1.0178],\n",
      "        [1.3653, 1.0086],\n",
      "        [1.4025, 1.0361]])\n"
     ]
    }
   ],
   "source": [
    "sa_v1 = SelfAttentionV1(d_in, d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a68bb5-be6f-483a-8b65-ec4764392325",
   "metadata": {},
   "source": [
    "- These are the context vectors corrensponing to our inputs\n",
    "- Since inputs contains six embedding vectors, we get a matrix storing the six context vectors, as shown in the above result.\n",
    "- We can improve the SelfAttention_v1 implementation further by utilizing PyTorch's nn.Linear layers, which effectively perform matrix multiplication when the bias units are disabled.\n",
    "- Additionally, a significant advantage of using nn.Linear instead of manually implementing nn.Parameter(torch.rand(...)) is that nn.Linear has an optimized weight initialization scheme, contributing to more stable and effective model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3360b52-6e95-413b-a6a9-cc9c39f4efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionV2(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96c5807d-9ef5-4c39-b07a-4d0632784b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttentionV2(d_in, d_out)\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5cc8a6-08ac-42f5-8f80-b5efd22ca8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
