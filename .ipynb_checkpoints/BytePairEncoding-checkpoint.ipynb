{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b02e2f-79e5-418d-9ffa-a329eca6659b",
   "metadata": {},
   "source": [
    "# Byte Pair Encoding (BPE) Tokenization \n",
    "\n",
    "Byte Pair Encoding is a sub-word tokenization techniuqe which helps us tackle a few problems that word-tokenization and character-tokenization fail to address. \n",
    "\n",
    "## Problems that BPE solves\n",
    "- In word tokenizaition each word in the document gets its own token-id, which will be represented as an embedding. Howver there are ~ 172,000 words in the english language. Encoding each word is not effective. Also, there will always be a chance that our model might encounter a word that is not in the vocabulary. BPE solves this by identifying the byte pairs with highest frequency and considering them as a single token and leaving the words with lower frequencies to form tokens of their own.\n",
    "- This helps in identifying sub-words, which solves the \"out-of-vocabulary word\" issue. Also, the size of the vocabulary will be significantly lower than in the case of word-tokenization\n",
    "- The other porblem it solves that character-level tokenization cannot solve is \"loss of meaning\". Words like \"finest\" and \"lowest\" have a commoan suffix (est), character-level tokenization simply cannot caputer this insight.  \n",
    "\n",
    "```\n",
    "{'old</w>': 7, 'older</w>': 3, 'finest</w>': 9, 'lowest</w>': 4}\n",
    "```\n",
    "\n",
    "## Initial Setup\n",
    "\n",
    "First, we need to break each word into individual characters:\n",
    "\n",
    "```\n",
    "old</w>    → o l d </w>    (count: 7)\n",
    "older</w>  → o l d e r </w> (count: 3)\n",
    "finest</w> → f i n e s t </w> (count: 9)\n",
    "lowest</w> → l o w e s t </w> (count: 4)\n",
    "```\n",
    "\n",
    "## Iteration 1\n",
    "\n",
    "Let's count all byte pairs (adjacent characters):\n",
    "\n",
    "| Byte Pair | Count | Calculation |\n",
    "|-----------|-------|-------------|\n",
    "| o+l      | 7     | From 'old</w>' (7) |\n",
    "| l+d      | 7     | From 'old</w>' (7) |\n",
    "| d+</w>   | 7     | From 'old</w>' (7) |\n",
    "| o+l      | 3     | From 'older</w>' (3) |\n",
    "| l+d      | 3     | From 'older</w>' (3) |\n",
    "| d+e      | 3     | From 'older</w>' (3) |\n",
    "| e+r      | 3     | From 'older</w>' (3) |\n",
    "| r+</w>   | 3     | From 'older</w>' (3) |\n",
    "| f+i      | 9     | From 'finest</w>' (9) |\n",
    "| i+n      | 9     | From 'finest</w>' (9) |\n",
    "| n+e      | 9     | From 'finest</w>' (9) |\n",
    "| e+s      | 9     | From 'finest</w>' (9) |\n",
    "| s+t      | 9     | From 'finest</w>' (9) |\n",
    "| t+</w>   | 9     | From 'finest</w>' (9) |\n",
    "| l+o      | 4     | From 'lowest</w>' (4) |\n",
    "| o+w      | 4     | From 'lowest</w>' (4) |\n",
    "| w+e      | 4     | From 'lowest</w>' (4) |\n",
    "| e+s      | 4     | From 'lowest</w>' (4) |\n",
    "| s+t      | 4     | From 'lowest</w>' (4) |\n",
    "| t+</w>   | 4     | From 'lowest</w>' (4) |\n",
    "\n",
    "Total counts for each pair:\n",
    "- o+l: 7+3 = 10\n",
    "- l+d: 7+3 = 10\n",
    "- d+</w>: 7\n",
    "- d+e: 3\n",
    "- e+r: 3\n",
    "- r+</w>: 3\n",
    "- f+i: 9\n",
    "- i+n: 9\n",
    "- n+e: 9\n",
    "- e+s: 9+4 = 13\n",
    "- s+t: 9+4 = 13\n",
    "- t+</w>: 9+4 = 13\n",
    "- l+o: 4\n",
    "- o+w: 4\n",
    "- w+e: 4\n",
    "\n",
    "The highest frequency pair is \"e+s\" with 13 occurrences, so we merge it into \"es\".\n",
    "\n",
    "## After Iteration 1\n",
    "\n",
    "```\n",
    "old</w>    → o l d </w>    (count: 7)\n",
    "older</w>  → o l d e r </w> (count: 3)\n",
    "finest</w> → f i n es t </w> (count: 9)\n",
    "lowest</w> → l o w es t </w> (count: 4)\n",
    "```\n",
    "\n",
    "## Iteration 2\n",
    "\n",
    "Now let's count all byte pairs again:\n",
    "\n",
    "| Byte Pair | Count | Calculation |\n",
    "|-----------|-------|-------------|\n",
    "| o+l      | 7     | From 'old</w>' (7) |\n",
    "| l+d      | 7     | From 'old</w>' (7) |\n",
    "| d+</w>   | 7     | From 'old</w>' (7) |\n",
    "| o+l      | 3     | From 'older</w>' (3) |\n",
    "| l+d      | 3     | From 'older</w>' (3) |\n",
    "| d+e      | 3     | From 'older</w>' (3) |\n",
    "| e+r      | 3     | From 'older</w>' (3) |\n",
    "| r+</w>   | 3     | From 'older</w>' (3) |\n",
    "| f+i      | 9     | From 'finest</w>' (9) |\n",
    "| i+n      | 9     | From 'finest</w>' (9) |\n",
    "| n+es     | 9     | From 'finest</w>' (9) |\n",
    "| es+t     | 9     | From 'finest</w>' (9) |\n",
    "| t+</w>   | 9     | From 'finest</w>' (9) |\n",
    "| l+o      | 4     | From 'lowest</w>' (4) |\n",
    "| o+w      | 4     | From 'lowest</w>' (4) |\n",
    "| w+es     | 4     | From 'lowest</w>' (4) |\n",
    "| es+t     | 4     | From 'lowest</w>' (4) |\n",
    "| t+</w>   | 4     | From 'lowest</w>' (4) |\n",
    "\n",
    "Total counts for each pair:\n",
    "- o+l: 7+3 = 10\n",
    "- l+d: 7+3 = 10\n",
    "- d+</w>: 7\n",
    "- d+e: 3\n",
    "- e+r: 3\n",
    "- r+</w>: 3\n",
    "- f+i: 9\n",
    "- i+n: 9\n",
    "- n+es: 9\n",
    "- es+t: 9+4 = 13\n",
    "- t+</w>: 9+4 = 13\n",
    "- l+o: 4\n",
    "- o+w: 4\n",
    "- w+es: 4\n",
    "\n",
    "The highest frequency pairs are now \"es+t\" and \"t+</w>\" with 13 occurrences each. Let's merge \"es+t\" into \"est\".\n",
    "\n",
    "## After Iteration 2\n",
    "\n",
    "```\n",
    "old</w>    → o l d </w>    (count: 7)\n",
    "older</w>  → o l d e r </w> (count: 3)\n",
    "finest</w> → f i n est </w> (count: 9)\n",
    "lowest</w> → l o w est </w> (count: 4)\n",
    "```\n",
    "\n",
    "## Iteration 3\n",
    "\n",
    "Let's count all byte pairs again:\n",
    "\n",
    "| Byte Pair | Count | Calculation |\n",
    "|-----------|-------|-------------|\n",
    "| o+l      | 7     | From 'old</w>' (7) |\n",
    "| l+d      | 7     | From 'old</w>' (7) |\n",
    "| d+</w>   | 7     | From 'old</w>' (7) |\n",
    "| o+l      | 3     | From 'older</w>' (3) |\n",
    "| l+d      | 3     | From 'older</w>' (3) |\n",
    "| d+e      | 3     | From 'older</w>' (3) |\n",
    "| e+r      | 3     | From 'older</w>' (3) |\n",
    "| r+</w>   | 3     | From 'older</w>' (3) |\n",
    "| f+i      | 9     | From 'finest</w>' (9) |\n",
    "| i+n      | 9     | From 'finest</w>' (9) |\n",
    "| n+est    | 9     | From 'finest</w>' (9) |\n",
    "| est+</w> | 9     | From 'finest</w>' (9) |\n",
    "| l+o      | 4     | From 'lowest</w>' (4) |\n",
    "| o+w      | 4     | From 'lowest</w>' (4) |\n",
    "| w+est    | 4     | From 'lowest</w>' (4) |\n",
    "| est+</w> | 4     | From 'lowest</w>' (4) |\n",
    "\n",
    "Total counts for each pair:\n",
    "- o+l: 7+3 = 10\n",
    "- l+d: 7+3 = 10\n",
    "- d+</w>: 7\n",
    "- d+e: 3\n",
    "- e+r: 3\n",
    "- r+</w>: 3\n",
    "- f+i: 9\n",
    "- i+n: 9\n",
    "- n+est: 9\n",
    "- est+</w>: 9+4 = 13\n",
    "- l+o: 4\n",
    "- o+w: 4\n",
    "- w+est: 4\n",
    "\n",
    "The highest frequency pair is now \"est+</w>\" with 13 occurrences, so we merge it into \"est</w>\".\n",
    "\n",
    "## After Iteration 3\n",
    "\n",
    "```\n",
    "old</w>    → o l d </w>    (count: 7)\n",
    "older</w>  → o l d e r </w> (count: 3)\n",
    "finest</w> → f i n est</w>  (count: 9)\n",
    "lowest</w> → l o w est</w>  (count: 4)\n",
    "```\n",
    "\n",
    "## Iteration 4\n",
    "\n",
    "Let's count all byte pairs again:\n",
    "\n",
    "| Byte Pair | Count | Calculation |\n",
    "|-----------|-------|-------------|\n",
    "| o+l      | 7     | From 'old</w>' (7) |\n",
    "| l+d      | 7     | From 'old</w>' (7) |\n",
    "| d+</w>   | 7     | From 'old</w>' (7) |\n",
    "| o+l      | 3     | From 'older</w>' (3) |\n",
    "| l+d      | 3     | From 'older</w>' (3) |\n",
    "| d+e      | 3     | From 'older</w>' (3) |\n",
    "| e+r      | 3     | From 'older</w>' (3) |\n",
    "| r+</w>   | 3     | From 'older</w>' (3) |\n",
    "| f+i      | 9     | From 'finest</w>' (9) |\n",
    "| i+n      | 9     | From 'finest</w>' (9) |\n",
    "| n+est</w>| 9     | From 'finest</w>' (9) |\n",
    "| l+o      | 4     | From 'lowest</w>' (4) |\n",
    "| o+w      | 4     | From 'lowest</w>' (4) |\n",
    "| w+est</w>| 4     | From 'lowest</w>' (4) |\n",
    "\n",
    "Total counts for each pair:\n",
    "- o+l: 7+3 = 10\n",
    "- l+d: 7+3 = 10\n",
    "- d+</w>: 7\n",
    "- d+e: 3\n",
    "- e+r: 3\n",
    "- r+</w>: 3\n",
    "- f+i: 9\n",
    "- i+n: 9\n",
    "- n+est</w>: 9\n",
    "- l+o: 4\n",
    "- o+w: 4\n",
    "- w+est</w>: 4\n",
    "\n",
    "The highest frequency pairs are \"o+l\" and \"l+d\" with 10 occurrences each. Let's merge \"o+l\" into \"ol\".\n",
    "\n",
    "## After Iteration 4\n",
    "\n",
    "```\n",
    "old</w>    → ol d </w>    (count: 7)\n",
    "older</w>  → ol d e r </w> (count: 3)\n",
    "finest</w> → f i n est</w>  (count: 9)\n",
    "lowest</w> → l o w est</w>  (count: 4)\n",
    "```\n",
    "\n",
    "## Iteration 5\n",
    "\n",
    "Let's count all byte pairs again:\n",
    "\n",
    "| Byte Pair | Count | Calculation |\n",
    "|-----------|-------|-------------|\n",
    "| ol+d     | 7     | From 'old</w>' (7) |\n",
    "| d+</w>   | 7     | From 'old</w>' (7) |\n",
    "| ol+d     | 3     | From 'older</w>' (3) |\n",
    "| d+e      | 3     | From 'older</w>' (3) |\n",
    "| e+r      | 3     | From 'older</w>' (3) |\n",
    "| r+</w>   | 3     | From 'older</w>' (3) |\n",
    "| f+i      | 9     | From 'finest</w>' (9) |\n",
    "| i+n      | 9     | From 'finest</w>' (9) |\n",
    "| n+est</w>| 9     | From 'finest</w>' (9) |\n",
    "| l+o      | 4     | From 'lowest</w>' (4) |\n",
    "| o+w      | 4     | From 'lowest</w>' (4) |\n",
    "| w+est</w>| 4     | From 'lowest</w>' (4) |\n",
    "\n",
    "Total counts for each pair:\n",
    "- ol+d: 7+3 = 10\n",
    "- d+</w>: 7\n",
    "- d+e: 3\n",
    "- e+r: 3\n",
    "- r+</w>: 3\n",
    "- f+i: 9\n",
    "- i+n: 9\n",
    "- n+est</w>: 9\n",
    "- l+o: 4\n",
    "- o+w: 4\n",
    "- w+est</w>: 4\n",
    "\n",
    "The highest frequency pair is now \"ol+d\" with 10 occurrences, so we merge it into \"old\".\n",
    "\n",
    "## After Iteration 5\n",
    "\n",
    "```\n",
    "old</w>    → old </w>    (count: 7)\n",
    "older</w>  → old e r </w> (count: 3)\n",
    "finest</w> → f i n est</w>  (count: 9)\n",
    "lowest</w> → l o w est</w>  (count: 4)\n",
    "```\n",
    "\n",
    "We could continue with more iterations, but this demonstrates the BPE process. \n",
    "We end the process of tokenization either when we get the desired vocabulary size or we run out of iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d494c8e-044a-400a-be6a-84f6d74a4d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/abhayjoshi/miniforge3/lib/python3.12/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/abhayjoshi/miniforge3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/abhayjoshi/miniforge3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/abhayjoshi/miniforge3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/abhayjoshi/miniforge3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
      "Downloading tiktoken-0.9.0-cp312-cp312-macosx_11_0_arm64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2024.11.6 tiktoken-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4980517c-7e63-432c-bf71-bdc8dabac216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "import tiktoken \n",
    "import importlib\n",
    "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "525675e1-10eb-414e-b2c8-648c56b0897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a79af31-159a-45c4-8396-29c1e837742c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1639, 1577, 475, 1310, 618, 345, 1577, 286, 534, 23309, 11, 220, 50256, 475, 618, 345, 2648, 534, 21452, 11, 345, 2897, 534, 2081, 12799, 13]\n"
     ]
    }
   ],
   "source": [
    "text = \"You give but little when you give of your possessions, <|endoftext|> but when you share your empathy, you offer your true essence.\"\n",
    "\n",
    "ids = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74774da0-1348-4910-8b3d-3c2397ad0796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You give but little when you give of your possessions, <|endoftext|> but when you share your empathy, you offer your true essence.\n"
     ]
    }
   ],
   "source": [
    "text = tokenizer.decode(ids)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ffd4dc-197d-417f-8242-5209eb93a73c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
